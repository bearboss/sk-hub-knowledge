title: kubesphere

date: 2021-05-25 15:20:37

tags: kubesphere

categories: kubesphere

copyright: true

sticky: 0

---

<span id="delete">

![](/images/banner/4.jpg)

</span>

<!--more-->
# 在线安装
```
yum -y install sudo  curl  openssl  ebtables  socat  ipset  ipvsadm  conntrack chrony
mkdir kubesphere
cd kubesphere

export KKZONE=cn
curl -sfL https://get-kk.kubesphere.io | VERSION=v3.0.13 sh -

./kk create config --with-kubesphere v3.4.1

vi config-sample.yaml
#修改节点, 单节点就是master 

#启动
./kk create cluster -f config-sample.yaml
```
# 离线安装- 基于在线安装好之后进行

```
原文地址: https://www.wolai.com/gefm/67hz7pPS2sqJBk4HCyr1VT

1. 创建mainifest文件
  ./kk create manifest
  如果是使用的是harbor私有仓库，那么把harbor docker-compose的注释给打开
  如果是使用的是docker-registry私有仓库，那么把docker-registry的注释给打开
  vi manifest-sample.yaml
    repository:
      iso:
        localPath: # 配置iso包路径 - 也就是centos 的包 因为装了yum的依赖,可能离线环境里面没有安装 比如conntrack
        url:
    ## 打开注释, 要注意harbor，compose的版本。 离线一般是用harbor
    # docker-registry:
    #   version: "2"
    # harbor:
    #   version: v2.4.1
    # docker-compose:
    #   version: v2.2.2
2.制作离线包  
  ./kk artifact export -m manifest-sample.yaml -o kubesphere.tar.gz
3.上传离线包 和kk环境包以及iso包到离线服务器
    iso放到 /root/kubekey/repository/amd64/centos/7/centos-7-amd64.iso
    
4.创建集群配置文件
  ./kk create config --with-kubesphere v3.3.2 --with-kubernetes v1.23.10 -f config-sample.yaml
  vi config-sample.yaml
    roleGroups:
      etcd:
      - master #这里修改为master
      control-plane: 
      - master #这里修改为master
      worker:
      - node1
      - node2
      # 设置使用 kk 自动部署镜像仓库的节点，一定要注意这个地方必须加上
      registry:
      - master
      
    registry:
      # 这里的类型设置为harbor
      type: harbor
      privateRegistry: ""
      namespaceOverride: ""
      registryMirrors: []
      insecureRegistries: [] 
        
5.创建镜像仓库
  ./kk init registry -f config-sample.yaml -a kubesphere.tar.gz
  
6.创建harbor仓库
  vim create_project_harbor.sh
  #!/usr/bin/env bash
  url="https://dockerhub.kubekey.local"  #修改url的值为https://dockerhub.kubekey.local
  user="admin"
  passwd="Harbor12345"
  harbor_projects=(library
      kubesphereio
      kubesphere
      argoproj
      calico
      coredns
      openebs
      csiplugin
      minio
      mirrorgooglecontainers
      osixia
      prom
      thanosio
      jimmidyson
      grafana
      elastic
      istio
      jaegertracing
      jenkins
      weaveworks
      openpitrix
      joosthofman
      nginxdemos
      fluent
      kubeedge
      openpolicyagent
  )
  for project in "${harbor_projects[@]}"; do
      echo "creating $project"
      curl -u "${user}:${passwd}" -X POST -H "Content-Type: application/json" "${url}/api/v2.0/projects" -d "{ \"project_name\": \"${project}\", \"public\": true}" -k #curl命令末尾加上 -k
  done
7.再次修改配置文件 vim config-sample.yaml
  配置harbor的地址
  registry:
    type: harbor
    auths:
      "dockerhub.kubekey.local":
        username: admin
        password: Harbor12345
    privateRegistry: "dockerhub.kubekey.local"
    namespaceOverride: "kubesphereio"
    registryMirrors: []
    insecureRegistries: []
  addons: []
8.推送仓库创建集群  
  ./kk create cluster -f config-sample.yaml -a kubesphere.tar.gz --with-packages
  如果不需要安装iso中的包那么就不需要加 `--with-packages`
  如果出现了k8s集群安装成功了，kubesphere长时间没有安装成功可以ctrl+c停止安装，使用以下命令重新安装，不用指定离线包了。
  ./kk create cluster -f config-sample.yaml
```
# 处理补全

```
apt-get install -y bash-completion
yum -y install -y bash-completion
echo 'source <(kubectl completion bash)' >>~/.bashrc
kubectl completion bash >/etc/bash_completion.d/kubectl
```



# 修改只能3000端口以上的问题

```
vi /etc/kubernetes/manifests/kube-apiserver.yaml

在 command 下添加 - --service-node-port-range=1-65535 参数

修改网关端口
kubectl edit svc kubesphere-router-kubesphere-system -n kubesphere-controls-system 

nodePort: xxxx为nodePort: 80

单独修改某个service的端口
kubectl edit svc sk-redis  -n test

```
# 生成一个模版

```
--dry-run 不运行
-oyaml 生成yaml
kubectl create deploy  --help 生成帮助函数

#生成模版
kubectl create deploy gitlab --image=gitlab/gitlab-ce:latest -oyaml --dry-run > gitlab.yaml

# svc
kubectl create svc nodeport
```

# 通过模版部署一个gitlab
```
#创建deployment
kubectl create deploy gitlab --image=gitlab/gitlab-ce:latest -oyaml --dry-run > gitlab.yaml

#追加svc
kubectl create svc nodeport gitlab --tcp=9005:80 -oyaml --dry-run >> gitlab.yaml

#修改文件内容 vi gitlab.yaml

apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: dev-deploy #新增
  creationTimestamp: null
  labels:
    app: gitlab
  name: gitlab
spec:
  replicas: 1
  selector:
    matchLabels:
      app: gitlab
  strategy: {}
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: gitlab
    spec:
      containers:
      - image: gitlab/gitlab-ce:latest
        name: gitlab-ce
        env:
        - name: GITLAB_ROOT_PASSWORD #新增
          value: admin123 #新增
---
apiVersion: v1
kind: Service
metadata:
  namespace: dev-deploy #新增
  creationTimestamp: null
  labels:
    app: gitlab
  name: gitlab
spec:
  ports:
  - name: 80-80
    port: 80
    protocol: TCP
    targetPort: 80
    nodePort: 30888 #新增
  selector:
    app: gitlab
  type: NodePort
status:
  loadBalancer: {}

kubectl apply -f gitlab.yaml
```
# 如果说需要加上持久化
```
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: dev-deploy
  labels:
    app: gitlab
  name: gitlab
spec:
  replicas: 1
  selector:
    matchLabels:
      app: gitlab
  template:
    metadata:
      labels:
        app: gitlab
      annotations:
        kubesphere.io/imagepullsecrets: '{}'
        logging.kubesphere.io/logsidecar-config: '{}'
    spec:
      containers:
        - name: container-c2tznc
          imagePullPolicy: IfNotPresent
          ports:
            - name: tcp-22
              protocol: TCP
              containerPort: 22
            - name: tcp-443
              protocol: TCP
              containerPort: 443
            - name: tcp-80
              protocol: TCP
              containerPort: 80
          image: 'gitlab/gitlab-ce:latest'
          env:
            - name: GITLIB_ROOT_PASSWORD
              value: Xhwl.@2023
          volumeMounts:
            - name: host-time
              mountPath: /etc/localtime
              readOnly: true
            - name: gitlab-pvc
              mountPath: /var/opt/gitlab
            - name: gitlab-pvc
              mountPath: /var/log/gitlab
            - name: gitlab-pvc
              mountPath: /etc/gitlab

      serviceAccount: default
      terminationGracePeriodSeconds: 30
      initContainers: []
      volumes:
        - hostPath:
            path: /etc/localtime
            type: ''
          name: host-time
        - name: gitlab-pvc
          persistentVolumeClaim:
            claimName: gitlab-pvc
      imagePullSecrets: null
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 25%
      maxSurge: 25%
---
apiVersion: v1
kind: Service
metadata:
  namespace: dev-deploy
  creationTimestamp: null
  labels:
    app: gitlab
  name: gitlab
spec:
  ports:
  - name: 80-80
    port: 80
    protocol: TCP
    targetPort: 80
    nodePort: 30888
  selector:
    app: gitlab
  type: NodePort
status:
  loadBalancer: {}

---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: gitlab-pv
  namespace: dev-deploy
spec:
  capacity:
    storage: 20Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  hostPath:
    path: /path/to/persistent/storage
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: gitlab-pvc
  namespace: dev-deploy
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
---
```
# 打包一个前端项目
```
# dockerfile配置 vi Dockerfile
  # 基础镜像
  FROM nginx
  # author
  MAINTAINER ruoyi
  
  # 挂载目录
  VOLUME /home/ruoyi/projects/ruoyi-ui
  # 创建目录
  RUN mkdir -p /home/ruoyi/projects/ruoyi-ui
  # 指定路径
  WORKDIR /home/ruoyi/projects/ruoyi-ui
  # 复制conf文件到路径
  COPY ./conf/nginx.conf /etc/nginx/nginx.conf
  # 复制html文件到路径
  COPY ./html/dist /home/ruoyi/projects/ruoyi-ui
  
# nginx通用配置 vi conf/nginx.conf
worker_processes  1;
events {
    worker_connections  1024;
}
http {
    include       mime.types;
    default_type  application/octet-stream;
    sendfile        on;
    keepalive_timeout  65;
    server {
        listen       80;
        server_name  _;
        location / {
            root   /home/ruoyi/projects/ruoyi-ui;
            try_files $uri $uri/ /index.html;
            index  index.html index.htm;
        }
        location /prod-api/{
            proxy_set_header Host $http_host;
            proxy_set_header X-Real-IP $proxy_add_x_forwarded_for;
            proxy_set_header REMOTE-HOST $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-For-test $proxy_add_x_forwarded_for;
            proxy_pass http://ruoyi-gateway.ruoyi:8080/;
        }
        # 避免actuator暴露
        if ($request_uri ~ "/actuator") {
            return 403;
        }
        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   html;
        }
    }
}
# 前端打包的静态文件
mkdir home/dist
```
# 打包一个后端项目
```
FROM openjdk:8-jdk
LABEL maintainer=afumu


#docker run -e PARAMS="--server.port 9090"
ENV PARAMS="--server.port=8080 --spring.profiles.active=prod --spring.cloud.nacos.discovery.server-addr=nacos.ruoyi:8848 --spring.cloud.nacos.config.server-addr=nacos.ruoyi:8848 --spring.cloud.nacos.config.namespace=prod --spring.cloud.nacos.config.file-extension=yml"
RUN /bin/cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime && echo 'Asia/Shanghai' >/etc/timezone

COPY target/*.jar /app.jar
EXPOSE 8080

#
ENTRYPOINT ["/bin/sh","-c","java -Dfile.encoding=utf8 -Djava.security.egd=file:/dev/./urandom -jar app.jar ${PARAMS}"]
```

# GITLAB RUNNER

```
mkdir gitlab-runner && cd gitlab-runner

helm repo list

helm repo add gitlab https://charts.gitlab.io/

helm search  repo -l gitlab-runner

helm pull gitlab/gitlab-runner --version 0.47.1 #版本要匹配上 - 对应15.6.1的gitlab

tar -zxvf gitlab-runner-0.47.1.tgz

cd gitlab-runner

vi values.yaml - 其他参数就helm启动时添加

runners: 增加配置
  config: |
    [[runners]]
      [runners.kubernetes]
        namespace = "{{.Release.Namespace}}"
        image = "ubuntu:16.04"
      [[runners.kubernetes.volumes.host_path]]
        name = "cache"
        mount_path = "/home/gitlab-runner/ci-build-cache"
        host_path = "/opt/cache"
      [[runners.kubernetes.volumes.host_path]]
        name = "docker"
        mount_path = "/var/run/docker.sock"
        read_only = true
        host_path = "/var/run/docker.sock"
        
前提要建一个gitlab-ci的命名空间 kubectl create namespace gitlab-ci --dry-run -oyaml > gitlab-ci.yaml
#卸载
helm uninstall -n gitlab-ci gitlab-runner

#创建 runnerRegistrationToken 在gitlab的runners中配置 runners.runUntagged 允许非标签的运行任务
helm install --namespace gitlab-ci gitlab-runner --set gitlabUrl=http://192.168.137.108 --set runners.runUntagged=true --set runnerRegistrationToken=pEs7tgHSfJ8qbxGqyMh1 --set runners.tags=k8s-runner --set rbac.create=true .
#验证
 kubectl get pod -n gitlab-ci
 kubectl describe pod gitlab-runner-68d588cc9-27p5v -n gitlab-ci
 在gitlab的runners中查看数量
```

# GITLAB AGENT

```
1. gitlab上配置

在gitlab项目中创建一个固定目录 .gitlab\agents\xx\  如xx是kubernetes-agent
创建空文件config.yaml

点击项目左侧  Infrastructure  > Kubernetes clusters > Connect a cluster 可以发现创建的kubernetes-agent #目录不要出错 否则下拉是空白

2.前提是gitlab开了gitlab-kas   高版本自动开 比如 15.6.1

docker exec -it gitlab bin/bash

	gitlab-ctl status
	run: gitlab-kas: (pid 1378) 1221s; run: log: (pid 805) 1421s
	#重启 gitlab-ctl restart
	
mkdir gitlab-agent && cd gitlab-agent

helm search repo -l gitlab-agent

helm pull gitlab/gitlab-agent  --version 1.8.0

tar -zxvf gitlab-agent-1.8.0.tgz

cd gitlab-agent

# 将第一步中弹出的命令粘贴下来
helm uninstall -n gitlab-ci gitlab-agent

helm repo add gitlab https://charts.gitlab.io
helm repo update

helm install gitlab-agent \
    --namespace gitlab-ci \
    --set image.tag=v15.6.0 \
    --set config.token=Z6zTERduFx7Pmvm1SMQXiKDqk42WANLhJGLVdTu7Q4VGYKQ_ew \
    --set config.kasAddress=ws://192.168.137.108/-/kubernetes-agent/ .
    
kubectl get pod  -n gitlab-ci

kubectl describe  pod gitlab-agent-57d599c445-2lrd2 -n gitlab-ci

kubectl logs -f gitlab-agent-57d599c445-2lrd2 -n gitlab-ci
#验证
 在gitlab的Kubernetes clusters中查看已连接就成功
 
#进入容器
kubectl exec  gitlab-runner-8466c47966-ljwdv --namespace=gitlab-ci -it -- bin/bash

```

# 外部节点操控集群

```
docker run -it centos:7 sh

whereis kubectl

scp -r root@192.168.137.108:/usr/local/bin/kubectl /usr/bin/

mkdir -p /root/.kube/

scp -r root@192.168.137.108:/root/.kube/config /root/.kube/

vi /etc/hosts
192.168.137.108  lb.kubesphere.local 

kubectl get pods -A
```

# docker scp ssh 免密登录

```
两个机器:docker1   108主机 

docker1上执行:
    mkdir -p ~/.ssh
    ssh-keygen -t rsa -P "" -f ~/.ssh/id_rsa
    scp ~/.ssh/id_rsa.pub root@192.168.137.108:/root/.ssh/authorized_keys

    就可以进行文件拷贝不需要密码了 
    scp root@192.168.137.108:/usr/local/bin/kubectl /usr/bin/
    mkdir -p /root/.kube/
    scp root@192.168.137.108:/root/.kube/config /root/.kube/
```



# 更新k8s

```
kubectl set image deployment spring-flow --namespace=project spring-flow=192.168.137.108:4000/ruoyi/spring-flow:9769c69d --record
```

# gitab-cicd

```
1. 每个项目根目录下创建.gitlab-ci.yml(更多的cicd配置模版文件请参考gitee上的项目k8s-deploy)
2. 编辑文件
stages:
  - package
  - image
  - deploy
variables:
  IMAGE_LOCAL_ADD: '192.168.137.108:4000'
  IMAGE_REMOTE_ADD: '192.168.137.108:5000'
  MAVEN_OPTS: "-Dmaven.repo.local=$CI_PROJECT_DIR/.m2/repository -Dmaven.test.skip"

package:
  stage: package
  image: maven:3.6.3-jdk-8
  variables:
    GIT_CHECKOUT: "true"   #下载代码
  cache: 
    key: maven-repo-cache
    paths:
    - $CI_PROJECT_DIR/.m2/repository
  before_script:
  script:
  - echo "=============== 设置settings.xml文件华为maven源  ==============="
  - mkdir -p $CI_PROJECT_DIR/.m2/
  - |
    echo '<settings xmlns="https://maven.apache.org/SETTINGS/1.2.0"
    xmlns:xsi="https://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="https://maven.apache.org/SETTINGS/1.2.0/ https://maven.apache.org/xsd/settings-1.2.0.xsd">
    <mirrors>
      <mirror>
        <id>aliyunmaven</id>
        <mirrorOf>*</mirrorOf>
        <name>阿里云公共仓库</name>
        <url>https://maven.aliyun.com/repository/public</url>
      </mirror>
    </mirrors>
    </settings>
    ' > $CI_PROJECT_DIR/.m2/settings.xml
  - echo "=============== 开始编译源码，在target目录生成jar文件 ==============="
  - MAVEN_PROFILE=${MAVEN_PROFILE:+"-P $MAVEN_PROFILE"}
  - mvn -am $MAVEN_PROFILE clean package $MAVEN_OPTS -s $CI_PROJECT_DIR/.m2/settings.xml

  rules:
    - if: $CI_COMMIT_TAG
    - if: $CI_PIPELINE_SOURCE == 'web'
  artifacts:
    paths:
      - target

image-build-push:
  stage: image
  image: docker:20.10.24-dind
  variables:
    GIT_CHECKOUT: "false"
  rules:
  - if: $CI_COMMIT_TAG
  - if: $CI_PIPELINE_SOURCE == 'web'   
  before_script:
  - echo "=============== 构建Dockerfile ================"
  - ls -l
  - |
    echo "FROM openjdk:8-jdk-alpine
        ENV TZ=Asia/Shanghai
        RUN ln -snf /usr/share/zoneinfo/\$TZ /etc/localtime && echo \$TZ > /etc/timezone
        RUN export LANG='zh_CN.UTF-8'
        ADD target/spring-flow-2.1.5.RELEASE.jar app.jar
        ENTRYPOINT java -Djava.security.egd=file:/dev/./urandom -jar /app.jar
        " > Dockerfile
  - ls -l
  script:
  - IMAGE_TAG=$([ "$CI_COMMIT_TAG" != "" ] && echo "$CI_COMMIT_TAG" || echo "$CI_COMMIT_SHORT_SHA")
  - TAG=$IMAGE_LOCAL_ADD/ruoyi/spring-flow:$IMAGE_TAG
  - docker build -t $TAG .
  - docker login $IMAGE_LOCAL_ADD -uadmin -pXhwl.@2023
  - docker push $TAG
  - echo "=============== 清理掉本次构建的镜像文件 ==============="
  - docker rmi -f $TAG

deploy:
  stage: deploy
  #image: centos:7.9.2009 - yum -y install openssh-clients sshpass expect
  image: 192.168.137.108:4000/ruoyi/centos:7.9.2009-scp
  variables:
    GIT_CHECKOUT: "false"
  rules:
  - if: $CI_COMMIT_TAG
  - if: $CI_PIPELINE_SOURCE == 'web'  
  before_script:
  - yum -y install openssh-clients sshpass expect
  - echo "=============== 修改host ================"
  - echo "192.168.137.108  lb.kubesphere.local" >> /etc/hosts
  - cat /etc/hosts
  - echo "=============== 传输kubectl ================"
  - touch a.sh && mkdir -p /root/.kube
  - ls -l
  - |
    echo '#!/bin/sh
          expect -c "
            spawn scp -r root@192.168.137.108:/usr/local/bin/kubectl /usr/bin/
            expect {
                \"*assword:\" {
                    send \"root\r\"
                    exp_continue
                }
                \"yes/no\" {
                    send \"yes\r\"
                    exp_continue
                }
                eof
            }
          "' > a.sh
  - |
    echo '#!/bin/sh
          expect -c "
            spawn scp -r root@192.168.137.108:/root/.kube/config /root/.kube/
            expect {
                \"*assword:\" {
                    send \"root\r\"
                    exp_continue
                }
                \"yes/no\" {
                    send \"yes\r\"
                    exp_continue
                }
                eof
            }
          "' > b.sh      
  - echo "=============== 脚本输入完成 ==============="
  - chmod +x a.sh && chmod +x b.sh && chmod +x /usr/bin/kubectl
  - cat a.sh
  - cat b.sh
  - ./a.sh
  - ./b.sh
  - cat /root/.kube/config
  script:
  - IMAGE_TAG=$([ "$CI_COMMIT_TAG" != "" ] && echo "$CI_COMMIT_TAG" || echo "$CI_COMMIT_SHORT_SHA")
  - TAG=$IMAGE_LOCAL_ADD/ruoyi/spring-flow:$IMAGE_TAG
  - kubectl set image deployment spring-flow --namespace=project spring-flow=$TAG
  - echo "=============== 部署完成 ==============="
```

如果遇到权限问题需要创建下面的Rabc

```
apiVersion: rbac.authorization.k8s.io/v1  
kind: ClusterRole  
metadata:  
  name: view-deployments  
rules:  
- apiGroups: ["apps"]  
  resources: ["deployments"]  
  verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1  
kind: ClusterRoleBinding  
metadata:  
  name: default-view-deployments  
subjects:  
- kind: ServiceAccount  
  name: default  
  namespace: gitlab-ci  
roleRef:  
  kind: ClusterRole  
  name: view-deployments  
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: rbac.authorization.k8s.io/v1  
kind: Role  
metadata:  
  namespace: project  
  name: view-deployments  
rules:  
- apiGroups: ["apps"]  
  resources: ["deployments"]  
  verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1  
kind: RoleBinding  
metadata:  
  namespace: project  
  name: default-view-deployments  
subjects:  
- kind: ServiceAccount  
  name: default  
  namespace: gitlab-ci  
roleRef:  
  kind: Role  
  name: view-deployments  
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: rbac.authorization.k8s.io/v1  
kind: Role  
metadata:  
  namespace: project  
  name: edit-deployments  
rules:  
- apiGroups: ["apps"]  
  resources: ["deployments"]  
  verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
---
apiVersion: rbac.authorization.k8s.io/v1  
kind: RoleBinding  
metadata:  
  namespace: project  
  name: default-edit-deployments  
subjects:  
- kind: ServiceAccount  
  name: default  
  namespace: gitlab-ci  
roleRef:  
  kind: Role  
  name: edit-deployments  
  apiGroup: rbac.authorization.k8s.io
```
